{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bBCU5u9kwNEF"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31m'Python 3.8.1 ('AdSTGCN')'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n","\u001b[1;31m다음 명령어를 실행하여 Python 환경에 'ipykernel'을(를) 설치합니다. \n","\u001b[1;31m 명령: 'conda install -n AdSTGCN ipykernel --update-deps --force-reinstall'"]}],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import glob\n","import re"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hvh5xbeawdkO"},"outputs":[],"source":["# 데이터 읽어들이기 및 DF 변환\n","folder = '/Users/user/Desktop/TermProjectCode/Data/@Transit_data'\n","Months = os.listdir(folder)\n","Months.reverse()\n","\n","Raw = []\n","Errors = []\n","\n","for i in range(len(Months)) :\n","  try :\n","    raw = pd.read_csv(folder + '/' + Months[i], encoding='cp949', index_col='사용일자')\n","    Raw.append(raw)\n","  except :\n","    Errors.append(Months[i])\n","    \n","for i in range(len(Errors)) : \n","  try :\n","    pd.read_csv(folder + '/' + Errors[i], encoding='utf-8')\n","    raw_data = pd.read_csv(folder + '/' + Errors[5], encoding='utf-8').reset_index()\n","    raw_data.columns = ['사용일자', '노선명', '역명', '승차총승객수', '하차총승객수', '등록일자', 'NaN']\n","    raw_data = raw_data.drop(columns = [ 'NaN'])\n","    raw_data = raw_data.set_index('사용일자')\n","    Raw.append(raw_data)\n","  except : \n","    Errors.append(Errors[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oexsv3yOweAr"},"outputs":[],"source":["for i in range(len(Errors)) : \n","  try :\n","    pd.read_csv(folder + '/' + Errors[i], encoding='utf-8')\n","    raw_data = pd.read_csv(folder + '/' + Errors[5], encoding='utf-8').reset_index()\n","    raw_data.columns = ['사용일자', '노선명', '역명', '승차총승객수', '하차총승객수', '등록일자', 'NaN']\n","    raw_data = raw_data.drop(columns = [ 'NaN'])\n","    raw_data = raw_data.set_index('사용일자')\n","    Raw.append(raw_data)\n","  except : \n","    Errors.append(Errors[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MlnIk7WrwefL"},"outputs":[],"source":["def make_timeseries_dataset(Raw, data_contents) :\n","  \"\"\"ST-GNN 인풋을 위한 데이터셋을 생성하는 프로세스로, 인풋으로는 합치고자 하는 달(Months)과, 생성하고자하는 데이터 종류(type)으로 나뉜다. 이때 type는 : 전체승객수, 승차총승객수, 하차총승객수 \"\"\"\n","\n","  months_df = []\n","\n","  # 달별 데이터 합치기\n","  for i in range(len(Raw)) :\n","    month = Raw[i].reset_index()\n","    month = month.drop(columns=['등록일자'])\n","    month['전체승객수'] = month['승차총승객수'] + month['하차총승객수'] # 전체승객수 데이터셋\n","\n","    Day = month['사용일자'].unique() # 일자별 데이터\n","    month = month.set_index('사용일자')\n","    days_df = []\n","\n","    # 일별 데이터 합치기\n","    for j in range(len(Day)) : \n","      day = month.loc[Day[j]]\n","      day = day.set_index(keys=['역명', '노선명'])\n","      day = day[[data_contents]]\n","      day = day.rename(columns = {data_contents : str(Day[j])})\n","      day = day.sort_index()\n","      if day.index.is_unique == False : # 중복되는 인덱스 제거\n","        day = day.groupby(level=[0, 1]).max()\n","      days_df.append(day)\n","\n","    output_days = pd.concat(days_df, axis=1, join='outer') # 일자별 취합\n","    months_df.append(output_days)\n","\n","  output_months = pd.concat(months_df, axis=1, join='outer') # 월별 취합\n","\n","  # 같은 '역명'이지만, 이름이 바뀐 역 데이터 취합\n","  \n","  return output_months\n","\n","def duplicate_data_processing(data) :\n","  \"\"\"생성된 데이터는 역 이름이 바뀜에 따라 중복되는 데이터들 존재(ex: 숭실대입구, 숭실대입구(살피재)), 이 데이터들을 '역명'을 기준으로 합치는 함수\"\"\"\n","\n","  # (1) 중복되는 역 이름 추출\n","  data_reset = data.reset_index()\n","  station_names = data_reset['역명'].unique()\n","  tofilter2 = [x for x in station_names if \"(\" and \")\" in x] # 괄호 있는 역\n","  tofilter1 = [re.sub(r'\\([^)]*\\)', \"\", x) for x in tofilter2] # 괄호 없는 역\n","  removal = [14, 22, 29, 34, 51, 52, 53, 59] # tofilter 중에 괄호만 있고 중복되지는 않는 역 인덱스\n","  tosubtract1 = [tofilter1[x] for x in removal]\n","  tosubtract2 = [tofilter2[x] for x in removal]\n","  filter1 = sorted(list(set(tofilter1) - set(tosubtract1)))\n","  filter2 = sorted(list(set(tofilter2) - set(tosubtract2)))\n","\n","  # (2) 중복 데이터 취합하기\n","  update = []\n","\n","  for i in range(len(filter1)) :\n","    try :\n","      filtered_data = data.loc[[filter1[i], filter2[i]]].reset_index()\n","      filtered_line = filtered_data['노선명'].unique() # 해당역에 포함된 노선 개수\n","\n","      for k in range(len(filtered_line)) :\n","        objective_data = filtered_data[filtered_data['노선명']==filtered_line[k]]\n","        concat_data = pd.DataFrame(objective_data.sum(), columns=['0']).transpose()\n","        concat_data['역명'] = filter1[i]\n","        concat_data['노선명'] = filtered_line[k]\n","        concat_data = concat_data.set_index(keys=['역명', '노선명'])\n","        update.append(concat_data)\n","\n","    except :\n","      print('error : {}'.format(i))\n","\n","  toreplace = pd.concat(update, axis=0, join='outer').sort_index()\n","\n","  # (3) 원본 데이터프레임 'data'로부터 대상 목록 제거하기\n","  filter = sorted(list(set(filter1) | set(filter2)))\n","  data_filtered = data.drop(filter)\n","\n","  # (4) 3번으로부터 제거된 데이터프레임 'data_filtered'와 새로 끼워넣을 'toreplace' 합치기\n","  final = pd.concat([data_filtered, toreplace], axis=0, join='outer')\n","  final = final.groupby(['역명']).sum()\n","\n","  return final\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-rtIwHlvwekL"},"outputs":[],"source":["data = make_timeseries_dataset(Raw, '전체승객수')\n","\n","# (1) 중복되는 역 이름 추출\n","data_reset = data.reset_index()\n","station_names = data_reset['역명'].unique()\n","tofilter2 = [x for x in station_names if \"(\" and \")\" in x] # 괄호 있는 역\n","tofilter1 = [re.sub(r'\\([^)]*\\)', \"\", x) for x in tofilter2] # 괄호 없는 역\n","removal = [14, 22, 29, 34, 51, 52, 53, 59] # tofilter 중에 괄호만 있고 중복되지는 않는 역 인덱스\n","tosubtract1 = [tofilter1[x] for x in removal]\n","tosubtract2 = [tofilter2[x] for x in removal]\n","filter1 = sorted(list(set(tofilter1) - set(tosubtract1)))\n","filter2 = sorted(list(set(tofilter2) - set(tosubtract2)))\n","\n","# (2) 중복 데이터 취합하기\n","update = []\n","\n","for i in range(len(filter1)) :\n","  try :\n","    filtered_data = data.loc[[filter1[i], filter2[i]]].reset_index()\n","    filtered_line = filtered_data['노선명'].unique() # 해당역에 포함된 노선 개수\n","\n","    for k in range(len(filtered_line)) :\n","      objective_data = filtered_data[filtered_data['노선명']==filtered_line[k]]\n","      concat_data = pd.DataFrame(objective_data.sum(), columns=['0']).transpose()\n","      concat_data['역명'] = filter1[i]\n","      concat_data['노선명'] = filtered_line[k]\n","      concat_data = concat_data.set_index(keys=['역명', '노선명'])\n","      update.append(concat_data)\n","\n","  except :\n","    print('error : {}'.format(i))\n","\n","toreplace = pd.concat(update, axis=0, join='outer').sort_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FegbRNadweox"},"outputs":[],"source":["filter = sorted(list(set(filter1) | set(filter2)))\n","data_filtered = data.drop(filter)\n","\n","final = pd.concat([data_filtered, toreplace], axis=0, join='outer')\n","final.to_csv('/Users/user/Desktop/TermProjectCode/Data/StationTotal.csv')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMU1JRkJMsYBtbDzqDsdt2y","provenance":[]},"kernelspec":{"display_name":"Python 3.8.1 ('AdSTGCN')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.1"},"vscode":{"interpreter":{"hash":"e868fbd7bced1391c57e5f2296fa32fca9fde70b3818119dcfce6c0251638158"}}},"nbformat":4,"nbformat_minor":0}
